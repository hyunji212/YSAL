{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html"
      ],
      "metadata": {
        "id": "luFcJrrrYpxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U openmim\n",
        "!mim install mmengine\n",
        "!mim install mmcv"
      ],
      "metadata": {
        "id": "SIUJ3HPcZdmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "RQfRCHwHMj6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGjkE2hVKdSH"
      },
      "outputs": [],
      "source": [
        "!rm -rf mmaction2\n",
        "!git clone https://github.com/open-mmlab/mmaction2.git\n",
        "%cd mmaction2\n",
        "\n",
        "!pip install -e .\n",
        "\n",
        "!pip install -r requirements/build.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/YOO-JS/Baseball_Batting_DeepLearning.git"
      ],
      "metadata": {
        "id": "go6ikccYMjj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "path = os.getcwd()\n",
        "print(path)"
      ],
      "metadata": {
        "id": "WSe6ybdZMjrB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ca0f8a0-1a33-4cc4-a87f-d1a530be45f7"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mmaction2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!mv ./Baseball_Batting_DeepLearning/baseball ./data"
      ],
      "metadata": {
        "id": "b6Ecx1TLMjtq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv ./Baseball_Batting_DeepLearning/config/tsm_1x1x8_50e_baseball_data.py ./configs/recognition/tsm/"
      ],
      "metadata": {
        "id": "2GvMFS8vMjyq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(path)"
      ],
      "metadata": {
        "id": "ZarrSDwK2Njb"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/train.py configs/recognition/tsm/tsm_1x1x8_50e_baseball_data.py --work-dir ./work_dirs/tsm_baseball_data\n",
        "\n",
        "#!python tools/train.py configs/recognition/tsm/tsm_1x1x8_50e_baseball_data.py"
      ],
      "metadata": {
        "id": "hn7eYUoeMj4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b725a49-eae7-4d1e-baa7-5d9c75f0f9ed"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config (path: configs/recognition/tsm/tsm_1x1x8_50e_baseball_data.py): {'preprocess_cfg': {'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375]}, 'model': {'type': 'Recognizer2D', 'backbone': {'type': 'ResNetTSM', 'pretrained': 'torchvision://resnet50', 'depth': 50, 'norm_eval': False, 'shift_div': 8, 'num_segments': 8}, 'cls_head': {'type': 'TSMHead', 'num_classes': 5, 'in_channels': 2048, 'spatial_type': 'avg', 'consensus': {'type': 'AvgConsensus', 'dim': 1}, 'dropout_ratio': 0.5, 'init_std': 0.001, 'is_shift': True, 'average_clips': 'prob', 'num_segments': 7}, 'data_preprocessor': {'type': 'ActionDataPreprocessor', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375]}, 'train_cfg': None, 'test_cfg': None}, 'train_cfg': {'type': 'EpochBasedTrainLoop', 'max_epochs': 50, 'val_begin': 1, 'val_interval': 1}, 'val_cfg': {'type': 'ValLoop'}, 'test_cfg': {'type': 'TestLoop'}, 'param_scheduler': [{'type': 'MultiStepLR', 'begin': 0, 'end': 50, 'by_epoch': True, 'milestones': [20, 40], 'gamma': 0.1}], 'optim_wrapper': {'constructor': 'TSMOptimWrapperConstructor', 'paramwise_cfg': {'fc_lr5': True}, 'optimizer': {'type': 'SGD', 'lr': 0.01, 'momentum': 0.9, 'weight_decay': 0.0001}, 'clip_grad': {'max_norm': 20, 'norm_type': 2}}, 'default_scope': 'mmaction', 'default_hooks': {'runtime_info': {'type': 'RuntimeInfoHook'}, 'timer': {'type': 'IterTimerHook'}, 'logger': {'type': 'LoggerHook', 'interval': 20, 'ignore_last': False}, 'param_scheduler': {'type': 'ParamSchedulerHook'}, 'checkpoint': {'type': 'CheckpointHook', 'interval': 3, 'save_best': 'auto', 'max_keep_ckpts': 3}, 'sampler_seed': {'type': 'DistSamplerSeedHook'}, 'sync_buffers': {'type': 'SyncBuffersHook'}}, 'env_cfg': {'cudnn_benchmark': False, 'mp_cfg': {'mp_start_method': 'fork', 'opencv_num_threads': 0}, 'dist_cfg': {'backend': 'nccl'}}, 'log_processor': {'type': 'LogProcessor', 'window_size': 20, 'by_epoch': True}, 'vis_backends': [{'type': 'LocalVisBackend'}], 'visualizer': {'type': 'ActionVisualizer', 'vis_backends': [{'type': 'LocalVisBackend'}]}, 'log_level': 'INFO', 'load_from': None, 'resume': False, 'dataset_type': 'VideoDataset', 'data_root': 'data/baseball/baseball_data/', 'data_root_val': 'data/baseball/baseball_data/', 'split': 1, 'ann_file_train': 'data/baseball/baseball_data_train.txt', 'ann_file_val': 'data/baseball/baseball_data_test.txt', 'ann_file_test': 'data/baseball/baseball_data_test.txt', 'file_client_args': {'io_backend': 'disk'}, 'train_pipeline': [{'type': 'DecordInit', 'io_backend': 'disk'}, {'type': 'SampleFrames', 'clip_len': 8, 'frame_interval': 8, 'num_clips': 1}, {'type': 'DecordDecode'}, {'type': 'Resize', 'scale': (-1, 256)}, {'type': 'MultiScaleCrop', 'input_size': 224, 'scales': (1, 0.875, 0.75, 0.66), 'random_crop': False, 'max_wh_scale_gap': 1, 'num_fixed_crops': 13}, {'type': 'Resize', 'scale': (224, 224), 'keep_ratio': False}, {'type': 'FormatShape', 'input_format': 'NCHW'}, {'type': 'PackActionInputs'}], 'val_pipeline': [{'type': 'DecordInit', 'io_backend': 'disk'}, {'type': 'SampleFrames', 'clip_len': 8, 'frame_interval': 8, 'num_clips': 1, 'test_mode': True}, {'type': 'DecordDecode'}, {'type': 'Resize', 'scale': (-1, 256)}, {'type': 'CenterCrop', 'crop_size': 224}, {'type': 'FormatShape', 'input_format': 'NCHW'}, {'type': 'PackActionInputs'}], 'test_pipeline': [{'type': 'DecordInit', 'io_backend': 'disk'}, {'type': 'SampleFrames', 'clip_len': 8, 'frame_interval': 8, 'num_clips': 10, 'test_mode': True}, {'type': 'DecordDecode'}, {'type': 'Resize', 'scale': (-1, 256)}, {'type': 'CenterCrop', 'crop_size': 224}, {'type': 'FormatShape', 'input_format': 'NCHW'}, {'type': 'PackActionInputs'}], 'train_dataloader': {'batch_size': 32, 'num_workers': 8, 'persistent_workers': True, 'dataset': {'type': 'VideoDataset', 'ann_file': 'data/baseball/baseball_data_train.txt', 'data_prefix': {'video': 'data/baseball/baseball_data/'}, 'pipeline': [{'type': 'DecordInit', 'io_backend': 'disk'}, {'type': 'SampleFrames', 'clip_len': 8, 'frame_interval': 8, 'num_clips': 1}, {'type': 'DecordDecode'}, {'type': 'Resize', 'scale': (-1, 256)}, {'type': 'MultiScaleCrop', 'input_size': 224, 'scales': (1, 0.875, 0.75, 0.66), 'random_crop': False, 'max_wh_scale_gap': 1, 'num_fixed_crops': 13}, {'type': 'Resize', 'scale': (224, 224), 'keep_ratio': False}, {'type': 'FormatShape', 'input_format': 'NCHW'}, {'type': 'PackActionInputs'}]}}, 'val_dataloader': {'batch_size': 32, 'num_workers': 8, 'persistent_workers': True, 'sampler': {'type': 'DefaultSampler', 'shuffle': False}, 'dataset': {'type': 'VideoDataset', 'ann_file': 'data/baseball/baseball_data_test.txt', 'data_prefix': {'video': 'data/baseball/baseball_data/'}, 'pipeline': [{'type': 'DecordInit', 'io_backend': 'disk'}, {'type': 'SampleFrames', 'clip_len': 8, 'frame_interval': 8, 'num_clips': 1, 'test_mode': True}, {'type': 'DecordDecode'}, {'type': 'Resize', 'scale': (-1, 256)}, {'type': 'CenterCrop', 'crop_size': 224}, {'type': 'FormatShape', 'input_format': 'NCHW'}, {'type': 'PackActionInputs'}], 'test_mode': True}}, 'test_dataloader': {'batch_size': 1, 'num_workers': 8, 'persistent_workers': True, 'sampler': {'type': 'DefaultSampler', 'shuffle': False}, 'dataset': {'type': 'VideoDataset', 'ann_file': 'data/baseball/baseball_data_test.txt', 'data_prefix': {'video': 'data/baseball/baseball_data/'}, 'pipeline': [{'type': 'DecordInit', 'io_backend': 'disk'}, {'type': 'SampleFrames', 'clip_len': 8, 'frame_interval': 8, 'num_clips': 10, 'test_mode': True}, {'type': 'DecordDecode'}, {'type': 'Resize', 'scale': (-1, 256)}, {'type': 'CenterCrop', 'crop_size': 224}, {'type': 'FormatShape', 'input_format': 'NCHW'}, {'type': 'PackActionInputs'}], 'test_mode': True}}, 'val_evaluator': {'type': 'AccMetric'}, 'test_evaluator': {'type': 'AccMetric'}, 'total_epochs': 50, 'auto_scale_lr': {'enable': False, 'base_batch_size': 256}, 'work_dir': './work_dirs/tsm_baseball_data', 'launcher': 'none', 'randomness': {'seed': None, 'diff_rank_seed': False, 'deterministic': False}}\n",
            "False\n",
            "01/23 10:34:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 966652320\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.2, V12.2.140\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.1.0+cu121\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.0+cu121\n",
            "    OpenCV: 4.8.0\n",
            "    MMEngine: 0.10.2\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 966652320\n",
            "    diff_rank_seed: False\n",
            "    deterministic: False\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "01/23 10:34:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "ann_file_test = 'data/baseball/baseball_data_test.txt'\n",
            "ann_file_train = 'data/baseball/baseball_data_train.txt'\n",
            "ann_file_val = 'data/baseball/baseball_data_test.txt'\n",
            "auto_scale_lr = dict(base_batch_size=256, enable=False)\n",
            "data_root = 'data/baseball/baseball_data/'\n",
            "data_root_val = 'data/baseball/baseball_data/'\n",
            "dataset_type = 'VideoDataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=3, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(ignore_last=False, interval=20, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    runtime_info=dict(type='RuntimeInfoHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    sync_buffers=dict(type='SyncBuffersHook'),\n",
            "    timer=dict(type='IterTimerHook'))\n",
            "default_scope = 'mmaction'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "file_client_args = dict(io_backend='disk')\n",
            "launcher = 'none'\n",
            "load_from = None\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        depth=50,\n",
            "        norm_eval=False,\n",
            "        num_segments=8,\n",
            "        pretrained='torchvision://resnet50',\n",
            "        shift_div=8,\n",
            "        type='ResNetTSM'),\n",
            "    cls_head=dict(\n",
            "        average_clips='prob',\n",
            "        consensus=dict(dim=1, type='AvgConsensus'),\n",
            "        dropout_ratio=0.5,\n",
            "        in_channels=2048,\n",
            "        init_std=0.001,\n",
            "        is_shift=True,\n",
            "        num_classes=5,\n",
            "        num_segments=7,\n",
            "        spatial_type='avg',\n",
            "        type='TSMHead'),\n",
            "    data_preprocessor=dict(\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='ActionDataPreprocessor'),\n",
            "    test_cfg=None,\n",
            "    train_cfg=None,\n",
            "    type='Recognizer2D')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=dict(max_norm=20, norm_type=2),\n",
            "    constructor='TSMOptimWrapperConstructor',\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0001),\n",
            "    paramwise_cfg=dict(fc_lr5=True))\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=True,\n",
            "        end=50,\n",
            "        gamma=0.1,\n",
            "        milestones=[\n",
            "            20,\n",
            "            40,\n",
            "        ],\n",
            "        type='MultiStepLR'),\n",
            "]\n",
            "preprocess_cfg = dict(\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ], std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ])\n",
            "randomness = dict(deterministic=False, diff_rank_seed=False, seed=None)\n",
            "resume = False\n",
            "split = 1\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='data/baseball/baseball_data_test.txt',\n",
            "        data_prefix=dict(video='data/baseball/baseball_data/'),\n",
            "        pipeline=[\n",
            "            dict(io_backend='disk', type='DecordInit'),\n",
            "            dict(\n",
            "                clip_len=8,\n",
            "                frame_interval=8,\n",
            "                num_clips=10,\n",
            "                test_mode=True,\n",
            "                type='SampleFrames'),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            ), type='Resize'),\n",
            "            dict(crop_size=224, type='CenterCrop'),\n",
            "            dict(input_format='NCHW', type='FormatShape'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='VideoDataset'),\n",
            "    num_workers=8,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(type='AccMetric')\n",
            "test_pipeline = [\n",
            "    dict(io_backend='disk', type='DecordInit'),\n",
            "    dict(\n",
            "        clip_len=8,\n",
            "        frame_interval=8,\n",
            "        num_clips=10,\n",
            "        test_mode=True,\n",
            "        type='SampleFrames'),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    ), type='Resize'),\n",
            "    dict(crop_size=224, type='CenterCrop'),\n",
            "    dict(input_format='NCHW', type='FormatShape'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "total_epochs = 50\n",
            "train_cfg = dict(\n",
            "    max_epochs=50, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
            "train_dataloader = dict(\n",
            "    batch_size=32,\n",
            "    dataset=dict(\n",
            "        ann_file='data/baseball/baseball_data_train.txt',\n",
            "        data_prefix=dict(video='data/baseball/baseball_data/'),\n",
            "        pipeline=[\n",
            "            dict(io_backend='disk', type='DecordInit'),\n",
            "            dict(\n",
            "                clip_len=8, frame_interval=8, num_clips=1,\n",
            "                type='SampleFrames'),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            ), type='Resize'),\n",
            "            dict(\n",
            "                input_size=224,\n",
            "                max_wh_scale_gap=1,\n",
            "                num_fixed_crops=13,\n",
            "                random_crop=False,\n",
            "                scales=(\n",
            "                    1,\n",
            "                    0.875,\n",
            "                    0.75,\n",
            "                    0.66,\n",
            "                ),\n",
            "                type='MultiScaleCrop'),\n",
            "            dict(keep_ratio=False, scale=(\n",
            "                224,\n",
            "                224,\n",
            "            ), type='Resize'),\n",
            "            dict(input_format='NCHW', type='FormatShape'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        type='VideoDataset'),\n",
            "    num_workers=8,\n",
            "    persistent_workers=True)\n",
            "train_pipeline = [\n",
            "    dict(io_backend='disk', type='DecordInit'),\n",
            "    dict(clip_len=8, frame_interval=8, num_clips=1, type='SampleFrames'),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    ), type='Resize'),\n",
            "    dict(\n",
            "        input_size=224,\n",
            "        max_wh_scale_gap=1,\n",
            "        num_fixed_crops=13,\n",
            "        random_crop=False,\n",
            "        scales=(\n",
            "            1,\n",
            "            0.875,\n",
            "            0.75,\n",
            "            0.66,\n",
            "        ),\n",
            "        type='MultiScaleCrop'),\n",
            "    dict(keep_ratio=False, scale=(\n",
            "        224,\n",
            "        224,\n",
            "    ), type='Resize'),\n",
            "    dict(input_format='NCHW', type='FormatShape'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=32,\n",
            "    dataset=dict(\n",
            "        ann_file='data/baseball/baseball_data_test.txt',\n",
            "        data_prefix=dict(video='data/baseball/baseball_data/'),\n",
            "        pipeline=[\n",
            "            dict(io_backend='disk', type='DecordInit'),\n",
            "            dict(\n",
            "                clip_len=8,\n",
            "                frame_interval=8,\n",
            "                num_clips=1,\n",
            "                test_mode=True,\n",
            "                type='SampleFrames'),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            ), type='Resize'),\n",
            "            dict(crop_size=224, type='CenterCrop'),\n",
            "            dict(input_format='NCHW', type='FormatShape'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='VideoDataset'),\n",
            "    num_workers=8,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(type='AccMetric')\n",
            "val_pipeline = [\n",
            "    dict(io_backend='disk', type='DecordInit'),\n",
            "    dict(\n",
            "        clip_len=8,\n",
            "        frame_interval=8,\n",
            "        num_clips=1,\n",
            "        test_mode=True,\n",
            "        type='SampleFrames'),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    ), type='Resize'),\n",
            "    dict(crop_size=224, type='CenterCrop'),\n",
            "    dict(input_format='NCHW', type='FormatShape'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    type='ActionVisualizer', vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/tsm_baseball_data'\n",
            "\n",
            "01/23 10:34:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "01/23 10:34:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SyncBuffersHook                    \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SyncBuffersHook                    \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Loads checkpoint by torchvision backend from path: torchvision://resnet50\n",
            "wrapped_name layer1.0.conv1.conv.net.weight\n",
            "wrapped_name layer1.1.conv1.conv.net.weight\n",
            "wrapped_name layer1.2.conv1.conv.net.weight\n",
            "wrapped_name layer2.0.conv1.conv.net.weight\n",
            "wrapped_name layer2.1.conv1.conv.net.weight\n",
            "wrapped_name layer2.2.conv1.conv.net.weight\n",
            "wrapped_name layer2.3.conv1.conv.net.weight\n",
            "wrapped_name layer3.0.conv1.conv.net.weight\n",
            "wrapped_name layer3.1.conv1.conv.net.weight\n",
            "wrapped_name layer3.2.conv1.conv.net.weight\n",
            "wrapped_name layer3.3.conv1.conv.net.weight\n",
            "wrapped_name layer3.4.conv1.conv.net.weight\n",
            "wrapped_name layer3.5.conv1.conv.net.weight\n",
            "wrapped_name layer4.0.conv1.conv.net.weight\n",
            "wrapped_name layer4.1.conv1.conv.net.weight\n",
            "wrapped_name layer4.2.conv1.conv.net.weight\n",
            "01/23 10:34:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - _IncompatibleKeys(missing_keys=[], unexpected_keys=['fc.weight', 'fc.bias'])\n",
            "01/23 10:34:43 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "01/23 10:34:43 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "01/23 10:34:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /content/mmaction2/work_dirs/tsm_baseball_data.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/mmaction2/tools/train.py\", line 144, in <module>\n",
            "    main()\n",
            "  File \"/content/mmaction2/tools/train.py\", line 140, in main\n",
            "    runner.train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/runner.py\", line 1777, in train\n",
            "    model = self.train_loop.run()  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 96, in run\n",
            "    self.run_epoch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 112, in run_epoch\n",
            "    self.run_iter(idx, data_batch)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 128, in run_iter\n",
            "    outputs = self.runner.model.train_step(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/model/base_model/base_model.py\", line 114, in train_step\n",
            "    losses = self._run_forward(data, mode='loss')  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmengine/model/base_model/base_model.py\", line 346, in _run_forward\n",
            "    results = self(**data, mode=mode)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/mmaction2/mmaction/models/recognizers/base.py\", line 262, in forward\n",
            "    return self.loss(inputs, data_samples, **kwargs)\n",
            "  File \"/content/mmaction2/mmaction/models/recognizers/base.py\", line 171, in loss\n",
            "    self.extract_feat(inputs,\n",
            "  File \"/content/mmaction2/mmaction/models/recognizers/recognizer2d.py\", line 142, in extract_feat\n",
            "    x = forward_once(inputs)\n",
            "  File \"/content/mmaction2/mmaction/models/recognizers/recognizer2d.py\", line 64, in forward_once\n",
            "    x = self.backbone(batch_imgs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/mmaction2/mmaction/models/backbones/resnet.py\", line 579, in forward\n",
            "    x = res_layer(x)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\", line 215, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/mmaction2/mmaction/models/backbones/resnet.py\", line 224, in forward\n",
            "    out = _inner_forward(x)\n",
            "  File \"/content/mmaction2/mmaction/models/backbones/resnet.py\", line 212, in _inner_forward\n",
            "    out = self.conv3(out)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/cnn/bricks/conv_module.py\", line 283, in forward\n",
            "    x = self.norm(x)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py\", line 171, in forward\n",
            "    return F.batch_norm(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\", line 2478, in batch_norm\n",
            "    return torch.batch_norm(\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 341.06 MiB is free. Process 419317 has 14.41 GiB memory in use. Of the allocated memory 13.82 GiB is allocated by PyTorch, and 476.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # 파일 경로\n",
        "# file_path = path + '/data/baseball/baseball_data_train.txt'\n",
        "\n",
        "# # 파일 열기 (탭을 띄어쓰기로 변경하여 파일 수정)\n",
        "# with open(file_path, 'r') as file:\n",
        "#     content = file.read()\n",
        "\n",
        "# content.count(\"/t\")\n",
        "# content = content.replace('\\t', ' ')  # 탭을 띄어쓰기로 변경\n",
        "\n",
        "# # 수정한 내용을 파일에 다시 쓰기\n",
        "# with open(file_path, 'w') as file:\n",
        "#     file.write(content)\n"
      ],
      "metadata": {
        "id": "SASEEKGHyl9W"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# file_path = path + '/data/baseball/baseball_data_test.txt'\n",
        "\n",
        "# # 파일 열기 (탭을 띄어쓰기로 변경하여 파일 수정)\n",
        "# with open(file_path, 'r') as file:\n",
        "#     content = file.read()\n",
        "\n",
        "# content = content.replace('\\t', ' ')  # 탭을 띄어쓰기로 변경\n",
        "\n",
        "# # 수정한 내용을 파일에 다시 쓰기\n",
        "# with open(file_path, 'w') as file:\n",
        "#     file.write(content)"
      ],
      "metadata": {
        "id": "9iHGeCC613qE"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#os.listdir(path + \"/data/baseball/baseball_data\")"
      ],
      "metadata": {
        "id": "CtviR7b613xw"
      },
      "execution_count": 71,
      "outputs": []
    }
  ]
}